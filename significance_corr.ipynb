{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import util\n",
    "import time\n",
    "import os \n",
    "import itertools\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEBASTIEN URCHS\n",
    "def p_permut(empirical_value, permutation_values):\n",
    "    n_permutation = len(permutation_values)\n",
    "    if empirical_value >= 0:\n",
    "        return (np.sum(permutation_values > empirical_value)+1) / (n_permutation + 1)\n",
    "    return (np.sum(permutation_values < empirical_value)+1) / (n_permutation + 1)\n",
    "\n",
    "def filter_fdr(df,contrasts):\n",
    "    df_filtered = df[(df['pair0'].isin(contrasts)) | (df['pair1'].isin(contrasts))]\n",
    "    _,fdr,_,_ = multipletests(df_filtered['pval'],method='fdr_bh')\n",
    "    df_filtered['fdr_filtered'] = fdr\n",
    "    return df_filtered\n",
    "\n",
    "def mat_form(df,contrasts,value = 'betamap_corr'):\n",
    "    n = len(contrasts)\n",
    "    d = dict(zip(contrasts,range(n)))\n",
    "    mat = np.zeros((n,n))\n",
    "    for c in contrasts:\n",
    "        #fill out vertical strip of mat\n",
    "        for i in range(n):\n",
    "            if (i == d[c]):\n",
    "                val = 1\n",
    "            else:\n",
    "                val = df[((df['pair0']==c)|(df['pair1']==c))\n",
    "                                & ((df['pair0']==contrasts[i])|(df['pair1']==contrasts[i]))][value]\n",
    "            mat[i,d[c]] = val\n",
    "            mat[d[c],i] = val\n",
    "    return pd.DataFrame(mat,columns=contrasts,index=contrasts)\n",
    "\n",
    "def make_matrices(df,contrasts,fdr = 'fdr_filtered'):\n",
    "    \"Param fdr can be set to 'fdr_filtered': FDR is performed using the pvalues only from the chosen contrasts\"\n",
    "    \"                              or 'fdr': values taken from FDR performed on full set of 42 contrasts\"\n",
    "    if (fdr == 'fdr_filtered'):\n",
    "        df = filter_fdr(df,contrasts)\n",
    "    mat_corr = mat_form(df,contrasts,value = 'betamap_corr')\n",
    "    mat_pval = mat_form(df,contrasts,value = 'pval')\n",
    "    mat_fdr = mat_form(df,contrasts,value = fdr)\n",
    "    return mat_corr,mat_pval,mat_fdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = ['DEL15q11_2','DUP15q11_2','DUP15q13_3_CHRNA7','DEL2q13','DUP2q13','DEL16p13_11','DUP16p13_11','DEL13q12_12','DUP13q12_12',\n",
    "        'DEL17p12','DUP17p12','TAR_dup','NRXN1del','DEL1q21_1','DUP1q21_1','DEL22q11_2','DUP22q11_2','DEL16p11_2','DUP16p11_2',\n",
    "      'SZ','BIP','ASD','ADHD']\n",
    "prs = ['Stand_PRS_newCDG2_ukbb','Stand_PRS_ASD','Stand_PRS_SCZ','Stand_PRS_MDD','Stand_PRS_IQ', 'Stand_PRS_BMI','Stand_PRS_height',\n",
    "       'Stand_PRS_T2D','Stand_PRS_LDL','Stand_PRS_CKD','Stand_PRS_SA','Stand_PRS_thickness','Stand_PRS_IBD_ukbb']\n",
    "cont = prs + ['CT','SA','Vol','fluid_intelligence_score_all','Gfactor','Neuroticism']\n",
    "\n",
    "maps = cases + cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths\n",
    "Only interested in mean corrected betamaps for correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_path_mc = '/home/harveyaa/Documents/fMRI/data/ukbb_9cohorts/null_models/{}_null_model_mc.npy'\n",
    "cont_n_path_mc = '/home/harveyaa/Documents/fMRI/data/ukbb_9cohorts/null_models_continuous/{}_null_model_mc.npy'\n",
    "\n",
    "b_path_mc = '/home/harveyaa/Documents/clara_paper/drop_maillard_15q11_2del/cc_{}_results_mc.csv'\n",
    "cont_b_path_mc = '/home/harveyaa/Documents/clara_paper/drop_maillard_15q11_2del/cont_{}_results_mc.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load null models and betamaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = []\n",
    "beta = []\n",
    "beta_std = []\n",
    "for c in cases:\n",
    "    null.append(pd.DataFrame(np.load(n_path_mc.format(c))))\n",
    "    beta.append(pd.read_csv(b_path_mc.format(c))['betas'].values) #unstandardized betas\n",
    "    beta_std.append(pd.read_csv(b_path_mc.format(c))['betas_std'].values) #standardized betas\n",
    "    \n",
    "\n",
    "for c in cont:\n",
    "    null.append(pd.DataFrame(np.load(cont_n_path_mc.format(c))))\n",
    "    if c not in prs:\n",
    "        c = '{}_z'.format(c)\n",
    "    beta.append(pd.read_csv(cont_b_path_mc.format(c))['betas'].values) #unstandardized betas\n",
    "    beta_std.append(pd.read_csv(cont_b_path_mc.format(c))['betas_std'].values) #unstandardized betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "betamaps = pd.DataFrame(beta,index=maps)\n",
    "betamaps_std = pd.DataFrame(beta_std,index=maps)\n",
    "nullmodels = pd.concat(null,keys=maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Find pvalues**\n",
    "- For whole connectome, and filtered to THAL and MOTnetDL:\n",
    "  - For each pair of contrasts:\n",
    "    - Generate a null distribution of correlations\n",
    "    - Get the actual correlation values\n",
    "    - Compare the actual correlation to the distribution to get the pvalue\n",
    "    \n",
    "### **Whole connectome**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get correlation distributions\n",
    "For each unique pair, between the real map of one and the null maps of the other and vice versa. Use unstandardized betas here (needs to match unstandardized betas of null)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/861\n",
      "50/861\n",
      "100/861\n",
      "150/861\n",
      "200/861\n",
      "250/861\n",
      "300/861\n",
      "350/861\n",
      "400/861\n",
      "450/861\n",
      "500/861\n",
      "550/861\n",
      "600/861\n",
      "650/861\n",
      "700/861\n",
      "750/861\n",
      "800/861\n",
      "850/861\n"
     ]
    }
   ],
   "source": [
    "n_pairs = int((len(maps))*(len(maps) -1)/2)\n",
    "corr = np.zeros((n_pairs,10000))\n",
    "\n",
    "pair = []\n",
    "l = 0\n",
    "for i in itertools.combinations(maps,2):\n",
    "    b = i[0]\n",
    "    n = i[1]\n",
    "    for j in range(5000):\n",
    "        corr[l,j] = pearsonr(betamaps.loc[b].values,nullmodels.loc[n].values[j,:])[0]\n",
    "        \n",
    "    b = i[1]\n",
    "    n = i[0]\n",
    "    for j in range(5000):\n",
    "        corr[l,j+5000] = pearsonr(betamaps.loc[b].values,nullmodels.loc[n].values[j,:])[0]\n",
    "    \n",
    "    pair.append(i)\n",
    "    if (l%50 == 0):\n",
    "        print('{}/{}'.format(l,n_pairs))\n",
    "    l = l + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(corr)\n",
    "df['pair'] = pair\n",
    "df.to_csv('correlation_dist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get actual correlations\n",
    "For each unique pair, correlation between betamaps. Use standardized betas here (as in rest of paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_bb = np.zeros(n_pairs)\n",
    "\n",
    "pair_bb = []\n",
    "l = 0\n",
    "for i in itertools.combinations(maps,2):\n",
    "    corr_bb[l] = pearsonr(betamaps_std.loc[i[0]].values,betamaps_std.loc[i[1]].values)[0]\n",
    "    \n",
    "    l = l + 1\n",
    "    pair_bb.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb = pd.DataFrame(corr_bb)\n",
    "df_bb['pair'] = pair_bb\n",
    "df_bb.to_csv('correlation_betas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['pair'] == df_bb['pair']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb = df_bb.rename(columns={0:'betamap_corr'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = df_bb.merge(df,on='pair')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = []\n",
    "for i in df_master.index:\n",
    "    p = p_permut(df_master.loc[i,'betamap_corr'],df_master[range(10000)].loc[i])\n",
    "    pval.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master['pval'] = pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair0 = [p[0] for p in pair]\n",
    "pair1 = [p[1] for p in pair]\n",
    "df_master['pair0'] = pair0\n",
    "df_master['pair1'] = pair1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compact = df_master[['pair0','pair1','betamap_corr','pval']]\n",
    "df_compact.to_csv('corr_pval.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filtered by region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.tri(64,k=0,dtype=bool)\n",
    "        \n",
    "THAL = np.zeros((64,64),bool)\n",
    "THAL[:,3] = True\n",
    "THAL_mask = THAL + np.transpose(THAL)\n",
    "THAL_mask = np.tril(THAL_mask)\n",
    "THAL_mask = THAL_mask[mask]\n",
    "        \n",
    "MOTnet_dl = np.zeros((64,64),bool)\n",
    "MOTnet_dl[:,55] = True\n",
    "MOTnet_dl_mask = MOTnet_dl + np.transpose(MOTnet_dl)\n",
    "MOTnet_dl_mask = np.tril(MOTnet_dl_mask)\n",
    "MOTnet_dl_mask = MOTnet_dl_mask[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Thalamus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter maps\n",
    "Filter betamaps and null models to only thalamus (region)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_THAL = [n.transpose()[THAL_mask].transpose() for n in null]\n",
    "beta_THAL = [b[THAL_mask] for b in beta]\n",
    "beta_std_THAL = [b[THAL_mask] for b in beta_std]\n",
    "\n",
    "betamaps_THAL = pd.DataFrame(beta_THAL,index=maps)\n",
    "betamaps_std_THAL = pd.DataFrame(beta_std_THAL,index=maps)\n",
    "nullmodels_THAL = pd.concat(null_THAL,keys=maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get correlation distributions\n",
    "For each unique pair, between the real map of one and the null maps of the other and vice versa. Use unstandardized betas here (needs to match unstandardized betas of null)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/861\n",
      "50/861\n",
      "100/861\n",
      "150/861\n",
      "200/861\n",
      "250/861\n",
      "300/861\n",
      "350/861\n",
      "400/861\n",
      "450/861\n",
      "500/861\n",
      "550/861\n",
      "600/861\n",
      "650/861\n",
      "700/861\n",
      "750/861\n",
      "800/861\n",
      "850/861\n"
     ]
    }
   ],
   "source": [
    "n_pairs = int((len(maps))*(len(maps) -1)/2)\n",
    "corr_THAL = np.zeros((n_pairs,10000))\n",
    "\n",
    "pair_THAL = []\n",
    "l = 0\n",
    "for i in itertools.combinations(maps,2):\n",
    "    b = i[0]\n",
    "    n = i[1]\n",
    "    for j in range(5000):\n",
    "        corr_THAL[l,j] = pearsonr(betamaps_THAL.loc[b].values,nullmodels_THAL.loc[n].values[j,:])[0]\n",
    "        \n",
    "    b = i[1]\n",
    "    n = i[0]\n",
    "    for j in range(5000):\n",
    "        corr_THAL[l,j+5000] = pearsonr(betamaps_THAL.loc[b].values,nullmodels_THAL.loc[n].values[j,:])[0]\n",
    "    \n",
    "    pair_THAL.append(i)\n",
    "    if (l%50 == 0):\n",
    "        print('{}/{}'.format(l,n_pairs))\n",
    "    l = l + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_THAL = pd.DataFrame(corr_THAL)\n",
    "df_THAL['pair'] = pair_THAL\n",
    "df_THAL.to_csv('correlation_dist_THAL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get actual correlations\n",
    "For each unique pair, correlation between betamaps. Use standardized betas here (as in rest of paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_bb_THAL = np.zeros(n_pairs)\n",
    "\n",
    "pair_bb_THAL = []\n",
    "l = 0\n",
    "for i in itertools.combinations(maps,2):\n",
    "    corr_bb_THAL[l] = pearsonr(betamaps_std_THAL.loc[i[0]].values,betamaps_std_THAL.loc[i[1]].values)[0]\n",
    "    \n",
    "    l = l + 1\n",
    "    pair_bb_THAL.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_THAL = pd.DataFrame(corr_bb_THAL)\n",
    "df_bb_THAL['pair'] = pair_bb_THAL\n",
    "df_bb_THAL.to_csv('correlation_betas_THAL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_THAL['pair'] == df_bb_THAL['pair']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_THAL = df_bb_THAL.rename(columns={0:'betamap_corr'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master_THAL = df_bb_THAL.merge(df_THAL,on='pair')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_THAL = []\n",
    "for i in df_master_THAL.index:\n",
    "    p = p_permut(df_master_THAL.loc[i,'betamap_corr'],df_master_THAL[range(10000)].loc[i])\n",
    "    pval_THAL.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master_THAL['pval'] = pval_THAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair0_THAL = [p[0] for p in pair_THAL]\n",
    "pair1_THAL = [p[1] for p in pair_THAL]\n",
    "df_master_THAL['pair0'] = pair0_THAL\n",
    "df_master_THAL['pair1'] = pair1_THAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compact_THAL = df_master_THAL[['pair0','pair1','betamap_corr','pval']]\n",
    "df_compact_THAL.to_csv('corr_pval_THAL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MOTnetDL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter maps\n",
    "Filter betamaps and null models to only thalamus (region)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_MOT = [n.transpose()[MOTnet_dl_mask].transpose() for n in null]\n",
    "beta_MOT = [b[MOTnet_dl_mask] for b in beta]\n",
    "beta_std_MOT = [b[MOTnet_dl_mask] for b in beta_std]\n",
    "\n",
    "betamaps_MOT = pd.DataFrame(beta_MOT,index=maps)\n",
    "betamaps_std_MOT = pd.DataFrame(beta_std_MOT,index=maps)\n",
    "nullmodels_MOT = pd.concat(null_MOT,keys=maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get correlation distributions\n",
    "For each unique pair, between the real map of one and the null maps of the other and vice versa. Use unstandardized betas here (needs to match unstandardized betas of null)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/861\n",
      "50/861\n",
      "100/861\n",
      "150/861\n",
      "200/861\n",
      "250/861\n",
      "300/861\n",
      "350/861\n",
      "400/861\n",
      "450/861\n",
      "500/861\n",
      "550/861\n",
      "600/861\n",
      "650/861\n",
      "700/861\n",
      "750/861\n",
      "800/861\n",
      "850/861\n"
     ]
    }
   ],
   "source": [
    "n_pairs = int((len(maps))*(len(maps) -1)/2)\n",
    "corr_MOT = np.zeros((n_pairs,10000))\n",
    "\n",
    "pair_MOT = []\n",
    "l = 0\n",
    "for i in itertools.combinations(maps,2):\n",
    "    b = i[0]\n",
    "    n = i[1]\n",
    "    for j in range(5000):\n",
    "        corr_MOT[l,j] = pearsonr(betamaps_MOT.loc[b].values,nullmodels_MOT.loc[n].values[j,:])[0]\n",
    "        \n",
    "    b = i[1]\n",
    "    n = i[0]\n",
    "    for j in range(5000):\n",
    "        corr_MOT[l,j+5000] = pearsonr(betamaps_MOT.loc[b].values,nullmodels_MOT.loc[n].values[j,:])[0]\n",
    "    \n",
    "    pair_MOT.append(i)\n",
    "    if (l%50 == 0):\n",
    "        print('{}/{}'.format(l,n_pairs))\n",
    "    l = l + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MOT = pd.DataFrame(corr_MOT)\n",
    "df_MOT['pair'] = pair_MOT\n",
    "df_MOT.to_csv('correlation_dist_MOT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get actual correlations\n",
    "For each unique pair, correlation between betamaps. Use standardized betas here (as in rest of paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_bb_MOT = np.zeros(n_pairs)\n",
    "\n",
    "pair_bb_MOT = []\n",
    "l = 0\n",
    "for i in itertools.combinations(maps,2):\n",
    "    corr_bb_MOT[l] = pearsonr(betamaps_std_MOT.loc[i[0]].values,betamaps_std_MOT.loc[i[1]].values)[0]\n",
    "    \n",
    "    l = l + 1\n",
    "    pair_bb_MOT.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_MOT = pd.DataFrame(corr_bb_MOT)\n",
    "df_bb_MOT['pair'] = pair_bb_MOT\n",
    "df_bb_MOT.to_csv('correlation_betas_MOT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_MOT['pair'] == df_bb_MOT['pair']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_MOT = df_bb_MOT.rename(columns={0:'betamap_corr'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master_MOT = df_bb_MOT.merge(df_MOT,on='pair')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_MOT = []\n",
    "for i in df_master_MOT.index:\n",
    "    p = p_permut(df_master_MOT.loc[i,'betamap_corr'],df_master_MOT[range(10000)].loc[i])\n",
    "    pval_MOT.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master_MOT['pval'] = pval_MOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair0_MOT = [p[0] for p in pair_MOT]\n",
    "pair1_MOT = [p[1] for p in pair_MOT]\n",
    "df_master_MOT['pair0'] = pair0_MOT\n",
    "df_master_MOT['pair1'] = pair1_MOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compact_MOT = df_master_MOT[['pair0','pair1','betamap_corr','pval']]\n",
    "df_compact_MOT.to_csv('corr_pval_MOT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('corr_pval.csv',index_col=0)\n",
    "df_THAL = pd.read_csv('corr_pval_THAL.csv',index_col=0)\n",
    "df_MOT = pd.read_csv('corr_pval_MOT.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = ['DEL15q11_2','DUP15q11_2','DUP15q13_3_CHRNA7','DEL2q13','DUP2q13','DEL16p13_11','DUP16p13_11','DEL13q12_12','DUP13q12_12',\n",
    "        'DEL17p12','DUP17p12','TAR_dup','NRXN1del','DEL1q21_1','DUP1q21_1','DEL22q11_2','DUP22q11_2','DEL16p11_2','DUP16p11_2',\n",
    "      'SZ','BIP','ASD','ADHD']\n",
    "prs = ['Stand_PRS_newCDG2_ukbb','Stand_PRS_ASD','Stand_PRS_SCZ','Stand_PRS_MDD','Stand_PRS_IQ', 'Stand_PRS_BMI','Stand_PRS_height',\n",
    "       'Stand_PRS_T2D','Stand_PRS_LDL','Stand_PRS_CKD','Stand_PRS_SA','Stand_PRS_thickness','Stand_PRS_IBD_ukbb']\n",
    "cont = prs + ['CT','SA','Vol','fluid_intelligence_score_all','Gfactor','Neuroticism']\n",
    "\n",
    "contrasts = cont + cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Make matrices**\n",
    " - Turn the large dataframe with one entry for each pair into readable correlation matrix form\n",
    "   - Use a specified subset of the contrasts\n",
    " - Return three matrices:\n",
    "   - Correlation between betamaps\n",
    "   - pvalues (from permutation test)\n",
    "   - FDR corrected pvalues\n",
    "     - FDR using given set of contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Whole connectome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-91cc07d6591e>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['fdr_filtered'] = fdr\n"
     ]
    }
   ],
   "source": [
    "#Example subset from figure 4\n",
    "subset = ['DEL1q21_1','DUP22q11_2','DEL22q11_2','Stand_PRS_ASD','BIP','SZ','Neuroticism',\n",
    "          'Stand_PRS_MDD','ASD','Stand_PRS_SCZ','DEL15q11_2','DUP16p11_2','DEL16p11_2',\n",
    "          'DUP1q21_1','Stand_PRS_SA','SA','DUP17p12','CT','Gfactor','fluid_intelligence_score_all','Stand_PRS_IQ']\n",
    "\n",
    "corr,pval,fdr = make_matrices(df,subset,fdr='fdr_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.to_csv('FC_corr_fig4_wholebrain_mc.csv')\n",
    "pval.to_csv('FC_corr_pval_fig4_wholebrain_mc.csv')\n",
    "fdr.to_csv('FC_corr_fdr_filtered_fig4_wholebrain_mc.csv')\n",
    "#fdr.to_csv('FC_corr_fdr_BY_filtered_fig4_wholebrain_mc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Thalamus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-91cc07d6591e>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['fdr_filtered'] = fdr\n"
     ]
    }
   ],
   "source": [
    "#Example subset from figure 5\n",
    "subset5 = ['CT','Gfactor','fluid_intelligence_score_all','Stand_PRS_IQ','Stand_PRS_SA',\n",
    "           'DUP17p12','SA','Stand_PRS_ASD','DUP16p11_2','DEL1q21_1','DUP22q11_2','DEL16p11_2',\n",
    "           'DUP1q21_1','DEL22q11_2','BIP','SZ','Neuroticism','ASD','DEL15q11_2',\n",
    "          'Stand_PRS_SCZ','Stand_PRS_MDD']\n",
    "\n",
    "corr_THAL,pval_THAL,fdr_THAL = make_matrices(df_THAL,subset5,fdr='fdr_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_THAL.to_csv('FC_corr_fig5_THAL_mc.csv')\n",
    "pval_THAL.to_csv('FC_corr_pval_fig5_THAL_mc.csv')\n",
    "fdr_THAL.to_csv('FC_corr_fdr_filtered_fig5_THAL_mc.csv')\n",
    "#fdr_THAL.to_csv('FC_corr_fdr_BY_filtered_fig5_THAL_mc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MOTnetDL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-91cc07d6591e>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['fdr_filtered'] = fdr\n"
     ]
    }
   ],
   "source": [
    "#Example subset from figure 6\n",
    "subset6 = ['CT','Gfactor','Stand_PRS_IQ','fluid_intelligence_score_all','DUP17p12','SA',\n",
    "           'Stand_PRS_SA','Stand_PRS_ASD','DUP1q21_1','DUP16p11_2','DEL16p11_2','Neuroticism',\n",
    "           'Stand_PRS_MDD','DEL22q11_2','BIP','SZ','DEL15q11_2','Stand_PRS_SCZ','ASD',\n",
    "          'DUP22q11_2','DEL1q21_1']\n",
    "\n",
    "corr_MOT,pval_MOT,fdr_MOT = make_matrices(df_MOT,subset6,fdr='fdr_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_MOT.to_csv('FC_corr_fig6_MOT_mc.csv')\n",
    "pval_MOT.to_csv('FC_corr_pval_fig6_MOT_mc.csv')\n",
    "fdr_MOT.to_csv('FC_corr_fdr_filtered_fig6_MOT_mc.csv')\n",
    "#fdr_MOT.to_csv('FC_corr_fdr_BY_filtered_fig6_MOT_mc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many correlations significant and survive FDR?\n",
    "Whole connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all:\n",
      "Survives FDR:  35 /210\n",
      "p<0.05:  82 /210\n"
     ]
    }
   ],
   "source": [
    "df21 = df[(df['pair0'].isin(subset))&(df['pair1'].isin(subset))]\n",
    "rej,fdr21,_,_ = multipletests(df21['pval'],method='fdr_bh')\n",
    "\n",
    "print('all:')\n",
    "print('Survives FDR: ',np.sum(rej),'/210')\n",
    "print('p<0.05: ',df21[df21['pval']<0.05].shape[0],'/210')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thal:\n",
      "Survives FDR:  4 /210\n",
      "p<0.05:  35 /210\n"
     ]
    }
   ],
   "source": [
    "df21_THAL = df_THAL[(df_THAL['pair0'].isin(subset5))&(df['pair1'].isin(subset5))]\n",
    "rej_THAL,fdr21_THAL,_,_ = multipletests(df21_THAL['pval'],method='fdr_bh')\n",
    "\n",
    "print('thal:')\n",
    "print('Survives FDR: ',np.sum(rej_THAL),'/210')\n",
    "print('p<0.05: ',df21_THAL[df21_THAL['pval']<0.05].shape[0],'/210')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mot:\n",
      "Survives FDR:  1 /210\n",
      "p<0.05:  62 /210\n"
     ]
    }
   ],
   "source": [
    "df21_MOT = df_MOT[(df_MOT['pair0'].isin(subset6))&(df['pair1'].isin(subset6))]\n",
    "rej_MOT,fdr21_MOT,_,_ = multipletests(df21_MOT['pval'],method='fdr_bh')\n",
    "\n",
    "print('mot:')\n",
    "print('Survives FDR: ',np.sum(rej_MOT),'/210')\n",
    "print('p<0.05: ',df21_MOT[df21_MOT['pval']<0.05].shape[0],'/210')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsfmri_gcn",
   "language": "python",
   "name": "rsfmri_gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
